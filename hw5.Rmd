---
title: "hw5"
author: "Shan Jiang"
date: "11/2/2018"
output: github_document
---
```{r}
library(tidyverse)
library(rvest)
library(ggplot2)
library(broom)

set.seed(1)
```

## Problem 1

##### Inspecting the file path and file names in the zip.
```{r}
file_path <- "./data/"
length(list.files(file_path))  # How many files are there?
list.files(file_path)  # Show all names
list.files(file_path)[11:20]  # Show last 10 names

```

Create a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time.


### Construct a dataframe using the `list.files` function
```{r message= FALSE}
## Construct a function to read the csv file
read_sheet <- function(path) {
   df = readr::read_csv(path) %>% 
   janitor::clean_names()
   
   df
}

## Construct the path 

base = "./data/"
p = list.files(file_path)
vec_name = str_c(base, c(p))

control_df = map_df(vec_name, read_sheet)

```

* Tidy the result: file names include the subject ID and arm.
```{r}
# Calling the ifelse function within mutate to label 2 Arms
control_df = control_df %>% View()
  mutate(ID = 1:20) %>% 
  mutate(Arm = ifelse(ID < 11, yes = "control", no = "exprimental")) %>%  
  select(Arm, ID, week_1:week_8) %>% 
  gather(key = No_week, value = measurement, week_1:week_8)

```

### Spaghetti plot 
```{r}
graph_1 = control_df %>% 
  ggplot(aes(x = No_week, y = measurement, group = ID)) +
  geom_line(aes(color = Arm))

graph_2 = control_df %>% 
ggplot(aes(x = No_week, y = measurement, group = ID)) +
  geom_line(aes(color = Arm)) + 
  facet_wrap(~ID) +
 theme(text = element_text(size = 9),
        axis.text.x = element_text(angle = 75, hjust = 1)) 

graph_1
graph_2
```

##### Comment on differences between groups.

From the above faceting Graph, we showed the absolute value of measurement and the gap of the two groups. 

1. On averge, subjects in the Experimental group attains a higher measurement value than that of subjects in control group from week 1 to 8. 
2. The experimental group presents a trend of increase across the weeks, which may indicates the exposure's potential effect on the patients with the effect of time. 
3. The control group patients acquired a more stable measurement in its outcome value, so it may indicates a lack of effect of exposure. 


## Problem 2

### Import the raw data.
```{r}
require(RCurl)
homicide_raw = read.csv( text = getURL("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"))
```

### Describe the raw data

The raw data focus on the homicide topic, which is originated from Washington Post github page. It organizes a total of `r nrow(homicide_raw)` cases from the year of 2007 to 2015, containing `r ncol(homicide_raw)` variables ranging from the demographical variables of the id, name, gender, age and race of the victim to the geographical and time information of the case. 

Next, we make a summary of the data in 51 US cities.
```{r}
homicide_raw = homicide_raw %>% 
  mutate(city_state = str_c(city, state, sep = "," )) %>% 
  mutate(city_state = as.factor(city_state)) %>% 
  group_by(city_state) 

```

* The total number of homicides grouped by cities, total city = 51.
```{r}
total_n  = homicide_raw %>% 
  group_by(city_state) %>%
  summarize(n = n()) 
```

* The number of unsolved homicides grouped by cities, total city = 50.
```{r}
unsolved_n  = homicide_raw %>% 
  group_by(city_state) %>%
  filter(disposition %in% c("Closed without arrest", "Open/No arrest"))%>% 
  summarize(n = n()) 

## Summary of dataframe
homicide_sum = left_join(unsolved_n, total_n, by = "city_state") %>% 
  rename(unsolved =  n.x , total_cases = n.y )

head(homicide_sum)
```

### Baltimore homicide rate test.  
```{r}
Bal_df = left_join(unsolved_n, total_n, by = "city_state") %>% 
          filter(city_state == "Baltimore,MD")

# apply the broom::tidy to this object
result = prop.test(Bal_df$n.x, Bal_df$n.y,
          alternative = "two.sided",
          correct = TRUE)

bal_tidy = tidy(result) 
 
# pull the estimated proportion and confidence intervals from the resulting tidy dataframe.
estimated_prop = function(i){
    estimate = pull(bal_tidy[i])
    return(estimate)
}

estimate = estimated_prop(1)
conf.low = estimated_prop(5)
conf.high = estimated_prop(6)

```

### All cities: Use the `prop.test` function for 50 cities.
```{r}
city_df = left_join(unsolved_n, total_n, by = "city_state") %>% 
  mutate( unsolved = n.x, total = n.y) %>% 
  select( city_state, unsolved, total)
  

## confidence interval for each.  
city = homicide_raw %>% 
   group_by(city_state) %>% 
   nest

un2 = homicide_raw %>% 
  group_by(city_state) %>%
  filter(disposition %in% c("Closed without arrest", "Open/No arrest")) %>% 
  distinct(city_state)

anti_join(city, un2, by = "city_state") %>% View()



sim_results = 
  tibble(i = 1:50) %>% 
  mutate(
    estimate_dfs = map(.x = beta1_true, ~simulate_n_regressions(n_runs = 10000, n = 30, beta1 = .x))
  )  
  
 sim_results %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(
    all = map_dbl(.x = data, ~ .x %>% pull(estimate) %>% ),
    signif = map_dbl(.x = data, ~ .x %>% filter(significant == 1) %>% pull(estimate) %>% mean)
  ) %>% 
  select(-data) %>% 
  gather(key = results, value = average, all:signif) 
```

Create a plot that shows the estimates and CIs for each city â€“ check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.


